\chapter{Visualization}
\label{ch:viz}

While the previous two chapters have focused on algorithmic uses of topic
models, one of the reasons for using topic models is that they produce
human-readable summaries of the themes of large document collections.  However,
for users to use the results of topic models, they must be able to understand
the models' output.  This depends on \emph{visualization} and \emph{interaction}
with the model.

We begin this chapter with a discussion of how best to show individual topics to
users.  From these foundations, we move to how we can display entire
models---with many topics---to users.  Finally, we close with how users can
provide feedback through these interfaces to improve the underlying model.

\section{Displaying Topics}
\label{sec:display}

Recall from the previous chapter that topics are distributions over words; the
words with the highest weight in a topic best explain what the topic is about.
While the simplest answer---just show the most probable words---is a common
solution, there are possible refinements that can improve a user's understanding
of a dataset by showing the relationships between words or explicitly showing
words' probability.

% cite TACL paper
\paragraph{Word Lists}

Just showing a list of the most common words (a
visualization that we'll call ``word list'') is very simple, it also works well.
Users can quickly understand what's going on, and it is an efficient use of
space.  represented horizontally~\cite{gardner2010topic,smith2015visual} or
vertically~\cite{eisenstein2012topicviz,chaney2012visualizing}, with or without
commas separating the individual words, or using set
notation~\cite{chaney2012visualizing}.  \citet{smith2015visual} go further by
adding bars representing the probabilities of the word.

\paragraph{Word Clouds}

Word clouds (e.g., Figure~\ref{fig:word-cloud}) are another popular approach for
displaying topics.  Unlike word lists, they also use the size of words to convey
additional information. Word clouds typically use the size of words to reflect
the probability of the words.  This uses more of a given visualization area to
be used to display a topic.

However, word clouds have been criticized for providing poor support for visual
search~\cite{Viegas2008} and lacking contextual information between
words~\cite{harris11}; users can sometimes draw false connections between words
that are placed next to each other randomly in a word cloud.  Another
alternative is to use word associations to layout
words~\citep{Smith:Chuang:Hu:Boyd-Graber:Findlater-2014};
Figure~\ref{fig:topic-in-a-box} shows places words that appear together next to
each other in the visualization.

\subsection{When Words aren't Enough}

Multi-word expressions can be discovered through
pre-processing~\citep{talley-11}, post-processing step~\citep{blei-09b},
or a joint model~\citep{johnson-10}.

\section{Labeling Topics}

Throughout this survey, we've been referring to topics about
\underline{information technology} or about \underline{the arts}.  These are
convenient labels, but completely removed from the raw distribution over words.
Thus, it's often useful to assign labels to topics within an interface.

% http://lms.comp.nus.edu.sg/sites/default/files/publication-attachments/pp0406-mao.pdf
% http://www.aclweb.org/anthology/P11-1154
% http://sifaka.cs.uiuc.edu/czhai/pub/kdd07-label.pdf
% http://demeter.inf.ed.ac.uk/redites/docs/vCoreTopicLabel.pdf
% http://www0.cs.ucl.ac.uk/staff/N.Aletras/resources/ACL14_Topic_Labelling.pdf
% http://www.aclweb.org/anthology/C10-2069

In contrast to the previous \emph{visualization} approaches, labeling
focuses son showing not the original words of a topic but rather a
clearer label more akin to what a human summary of the data would
provide.

Approaches for automatic labeling can be devided into those that only
use internal information from the topic model against those that also
use external knowledge resources.  While purely internal methods are
more robust and consistent with the philospohy of unsupervised topic
models, those that use external resources often produce higher quality
labels.

Of the techniques that use external reources, we further separate
those that use direct supervision for labeling (i.e., knowing what
consitatues a good labeling) from those that use general knowledge
resources such as Wikipedia or knowledge bases.

\paragraph{Internal Labeling} 

\citet{mei-07} propose an internal labeling method that takes
prominent phrases from the topic and compares how consistent the
phrase's context is is with the topic distribution.  Phrases whose
contexts closely resemble the topic often appear in regions of text
that summarize the document, making them good candidates for labels.
\cite{mao-12} extend the technique to hierarchies, using the insight
that parents’ labels should be consistent with their childrens'.

% What about Tim W at UIUC?

% I didn't really understand this paper: Automatic Labelling of Topic
% Models Learned from Twitter by Summarisation (shoud we cite?)

\paragraph{Labeling with Supervised Labels}

\citet{lau-10} use a supervised approach to rerank the words in a
topic to ensure that the „best“ word in the topic is shown to a
user.  Each candidate word forms a feature vector consisting of
features such as the following:
\begin{itemize*}
\item the conditional probability of a word given the other words in a
  topic (which implies topic coherence, as discussed in Section~\ref{});
\item whether the word is a hypernym of other words in the topic
  (e.g., ``dog'' in a topic that also contains ``terrier'' and
  ``poodle''); and
\item the original probability of the word in the topic.
\end{itemize*}

While these can be used alone as an unsupervised reranking,
\citet{lau-10} use user-selected best topic words to weight which of
these features are most important for selecting the best topic word.
These weights are learned using support vector regression~\cite{}.
\citet{lau-11} extend their technique by adding candidates from
Wikipedia to the set and show that models learned on different domain
corpora are still effective.

\paragraph{Labeling with Knowledge Bases}

% More details
\citet{magnatti-07} align hierarchical topic models with an external
ontology of labels.

\citet{aleteras-14} instead query the whole web and then build a graph
that includes the words that make up the titles of the retrieved
webpages. The edges between the words is the \abr{npmi} computed on a
reference corpus.  The intuition is that words that are ``central'' in
this graph will be a good title for the topic.

They find the central words by using the PageRank~\cite{} algorithm.
This finds words that are highly probable in the topic and appears
often with many other words in the topic.

\section{Displaying Models}

But a topic model is more than about individual topics.

It is important to show the most relevant documents for reach
topics~\citep{chaney-12}

More sophisticated techniques can give the relationship between meta
data and topics~\citep{gardner-10,eistenstein-14}

It is also important to show the similarity between
topics~\citep{chuang-12}

Showing the relationships between multiple models can also help
distinguish stable from spurious topics~\citep{chuang-15}

\section{Interaction}

\subsection{Improving Topics}

But not all topic models are perfect.  Visualizations can help show
users where topic models have issues.

One approach is to provide probabilistic constraints~\citep{hu-14:itm}

Another approach is to add matrix constraints~\citep{choo-13}

These interactions and visualizations allow users to discover and
refine insights, allowing them to explore and understand diverse
datasets.
