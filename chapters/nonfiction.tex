
\chapter{Historical Documents}
\label{ch:nonfiction}

Topic models play an important role in the analysis of historical documents.
Historical records tend to be extensive and difficult to manage without intense and time-consuming organization.
Records are complicated: they resist categorization, and may even lack standard spelling and formatting.
But there is more to history than simply the management of documents.
The task of a historian is not only to absorb the contents of historical records, but to generalize; to find patterns and regularities that are true to the documents, but also beyond any single piece of evidence.
Topic models are useful because they address these issues. They are scalable, robust to variability, and able to generalize while remaining grounded in observation.

Automated methods are an especially valuable counterpoint to traditional close reading methods.
Studying history is about encountering the unexpected, often in contexts that seem familiar.
We don't necessarily know how people in the past talked about particular issues, or how they organized their lives.
Perhaps more dangerously, we assume that we know these things, and that our ancestors saw the world in the same way we do.
Topic models give us a perspective that is interpretable but at the same time alien, based on patterns in documents and not on our own conceptions of how things should be.

Time is a critical variable in the study of historical documents.
Although many modern collections have a significant aspect of time variation (see for example scientometrics), time is a defining element of historical research.
Collections of historical documents are necessarily situated in a time other than our own, but also tend to cover long periods --- decades or even centuries.
As a result, many of the examples cited in this chapter organize documents along a temporal axis.
The associated analysis is particularly concerned with how language, as reflected in topic concentrations and topic contents, changes over time.

This chapter is organized around different formats for historical documents.
A recurring focus is the desire to plot events and discourses against time.
We begin with historical newspapers, which are relatively close to the modern news articles that are a more familiar use case in topic modeling.
We then consider other forms of historical records, such as annals and diaries.
These demonstrate the flexibility of topic modeling, including a corpus not in English and corpus in English with irregular spelling.
Finally, we consider studies of historical scholarly literature.

%A useful resource:
%Clay Templeton, Topic Modeling in the Humanities: An Overview.\footnote{http://mith.umd.edu/topic-modeling-in-the-humanities-an-overview/}

\section{Newspapers}

\cite{newman-06} present an example of topic modeling on historical newspapers, in a collection of articles from the {\em Pennsylvania Gazette} from 1728 to 1800.\cite{http://www.accessible-archives.com/}
These articles comprise 25 million word tokens in articles and advertisements, and cover several generations of everyday life before, during, and after the founding of the United States of America.
The authors contrast their study to manually created keyword-based indexes, which focus on specific terms and can be applied inconsistently across large corpora.
Spurious patterns in index term use could complicate historical research. 
They cite an example of the tag {\em adv}, which is used extensively in the early and late decades of the corpus, but not in the middle.
The topic-based approach is attractive because it is consistent across the collection (as long as the terms used in the documents are themselves consistent) and because it operates at a more abstract semantic level, reducing the chance that modern historians miss key terms. 

They compare three methods for finding semantic dimensions, latent semantic analysis \citep{deerwester-90}, k-means clustering, and a topic model \citep{hofmann-99}.
The difference between these methods can be described in terms of expressivity.
LSA is effective at embedding word types and documents in a low-dimensional space, but the individual dimensions of this space are not interpretable as themes.
LSA is too expressive: it places no constraints, such as positivity, on the learned dimensions, and therefore produces uninterpretable results that nevertheless fit the document set well.
The k-means clustering is more similar to the topic model, and more successful at finding recognizable themes.
But it is also prone to repeating similar clusters with small variations.
Because of the single-membership assumption (a document can only belong to one cluster), the clustering model cannot represent documents with varying combinations of somewhat independent themes.
The k-means model is therefore insufficiently expressive: it it forced to ``waste'' clusters on frequent combinations of simpler themes.
The topic model, in contrast, has both modeling flexibility along with sufficient  constraints to support interpretable results.

The authors find that the learned topics are a good representation of dynamics in the corpus, although not always in a direct manner.
There is a large increase in discussions of politics in the period immediately around the American Revolution ({\em state government constitution law united power}).
There is also evidence of economic factors: a topic relating to descriptions of cloth ({\em silk cotton ditto white black linen}) rises in the 1750s, but then declines as Americans turned to domestic ``homespun'' cloth production in response to British trade policies.
Other topics point to more subtle changes in language.
A topic that is less immediately interpretable ({\em  say thing might think own did}) corresponds to a series of long ``public letters'' that contain more academic ``argument making''.



Nelson\footnote{Mining the Dispatch, http://dsl.richmond.edu/dispatch/} studies topics in Civil War-era newspapers, including the Confederate paper of record, the Daily Dispatch, and the New York Times.

\cite{yang-11-historical} model a collection of historical newspapers from Texas, finding that the significance of the pivotal battle of San Jacinto was established much earlier than historians had anticipated.

\section{Historical Records}

Other types of records besides newspapers are of interest, and present their own challenges.
In this section we consider two case studies, in which the simplicity of the bag-of-words document model is an asset because it allows for substantial variability in spelling and language, both in English and in other languages.

Miller \cite{miller-13} uses Chinese records to investigate the meaning of the word {\em zei}, or ``bandit'' in Qing dynasty China. The word by itself can imply several different forms of anti-social behavior, which are difficult to distinguish from word frequencies alone. A topic model uses contextual information to separate these effects.

The application of topic models in Chinese highlights the importance of tokenization.
We usually receive documents in the form of long strings, but we are interested in identifying {\em tokens} that are short strings with a specific meaning.
Breaking a document into distinct tokens is an often-overlooked part of the document analysis process.
In European languages we can achieve good results simply by separating strings of letter characters from sequences of non-letter characters, although there are many special cases.
Tokens may contain non-letter characters such as apostrophes and hyphens, and may span multiple words ({\em Queen Victoria}, {\em black hole}).
In many East Asian writing systems we cannot rely on orthographic conventions to identify tokens.
Miller argues that in Classical Chinese a single character can be treated as a token without a strong negative impact on modeling, but for Japanese and modern Chinese we must often rely on pre-processing tools that are themselves potentially unreliable.

\jbgcomment{Could we get a figure for the months?  I think that would be a nice addition}

Cameron Blevins\footnote{http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/} models the diary of Martha Ballard, a revolutionary war-era midwife who recorded entries over 27 years. The model provides a useful way to discover connections between words and repeated discourses.
As with other historical corpora, Blevins focuses on the connection between topics and time.
Specific events, like a birth, can be highlighted by looking at spikes in a certain topic in the day-to-day time series.
But larger trends are also evident.
As a calibration experiment, Blevins measures the association of a topic that appears to refer to cold weather ({\em cold, windy, chilly, snowy, air}) to months of the year.
As expected, the concentration of this topic is lowest from May to August, rises from September to January, and falls from February to April.

Blevins identifies several other topics that appear to change in their concentration over time.
Two topics involving house work, focusing roughly on cleaning and cooking, respectively, appear to be correlated in time, and rise over the decades.
Blevins connects this finding to suggestions that as Ballard grew older and her children moved away, she had less help from family members.
A more subtle topic involves descriptions of fatigue and illness.
This topic also increases over time, and appears to correlate with the housework topics, except in the last year of the diary, where fatigue and illness reach their highest concentration and housework declines.

This analysis exemplifies the exploratory nature of topic modeling: by themselves, these observations are not conclusive, but they are suggestive and point to areas of further analysis.
A scholar might take the diary entries that score high on an individual topic as a reading list, and determine how well a particular automatically detected discourse maps to themes in Ballard's personal experience.
For example, one might check whether Ballard's references to fatigue and illness are referring to herself or to patients.
The model does not tell the whole story, but it points to where stories might lie.

Blevins argues that characteristics of the diary form make it well-suited for topic analysis: ``Short, content-driven entries that usually touch upon a limited number of topics appear to produce remarkably cohesive and accurate topics.''
In addition, the topic model's lack of linguistic sophistication is actually an asset in this case.
The diary is written in a terse style with many abbreviations and with irregular, 18th century spelling: ``mrss Pages illness Came on at Evng and Shee was Deliverd at 11h of a Son which waid 12 lb.''
Models trained on modern text corpora might not even recognize this example as English, but the topic modeling algorithm is still capable of finding semantically meaningful groups of words.



\section{Scholarly Literature}


\jbgcomment{The definition of secondary literature seems unclear to me, and it's not clear that the problem of copyright has been discussed enough that it's clear that JSTOR is so great as a result (even though it is!)}

The historical record of scholarship is a valuable source for intellectual history.
Many users make use of the JStor ``Data for Research'' API.\footnote{http://dfr.jstor.org/}
The DFR API is an important example, because it provides access to articles that have been scanned by JStor and may be under copyright.
Access to the underlying documents in their original form as readable sequences of words may be restricted for legal or commercial reasons.
DFR provides a simple view into selected articles by only providing the frequency of word unigrams.
While the bag-of-words assumption used by topic models is restrictive, in this case it can be an advantage, because the original sequence of words is not used for inference anyway.

\cite{Mimno-12b} studies a collection of Classics journals digitized by JStor to detect changes in the field over the 20th century.

\cite{Goldstone-14} use a topic model as a tool to structure an exploration of a corpus that spans more than a century.
They are interested both in changes at the topic level and at the level of word use within topics.
For these authors the appeal of topic modeling is that models are better able to represent contextual meaning than simple lists of keywords. They write that ``[t]he meanings
of words are shifting and context-dependent. For this reason, it’s risky to
construct groups of words that we imagine are equivalent to some predetermined
concept.''

They analyze the proceedings of the Modern Language Association to find shifts in focus in the field of English literature.
A model trained with 150 topics on 21,000 articles identifies a topic associated with descriptions of violence: {\em power,
violence, fear, blood, death, murder, act, guilt}. Using a temporal plot they argue that the concentration of this topic is greater in the second half of the 20th century than during the first half.
They contextualize this finding by comparing the frequency of these words in a more general corpus from Google ngrams; there is no comparable change.
This approach holds topic fixed and searches for associated words.
They then pivot and hold the word ``power'' fixed and search for associated topics.
In this case the {\em violence} topic actually appears to be relatively stable in its association with the target word. The largest increase is in a different topic characterized by the words {\em own power text form}, in which context it appears almost exclusively after 1980.

This is a subfield of a broader study of the science of science, which is discussed next.
