
\chapter{Historical Documents}
\label{ch:nonfiction}

Topic models play an important role in the analysis of historical documents.
Historical records tend to be extensive and difficult to manage without intense and time-consuming organization.
Records are complicated: they resist categorization, and may even lack standard spelling and formatting.
But there is more to history than simply the management of documents.
The task of a historian is not only to absorb the contents of historical records, but to generalize; to find patterns and regularities that are true to the documents, but also beyond any single piece of evidence.
Topic models are useful because they address these issues. They are scalable, robust to variability, and able to generalize while remaining grounded in observation.

Automated methods are an especially valuable counterpoint to traditional close reading methods.
Studying history is about encountering the unexpected, often in contexts that seem familiar.
We don't necessarily know how people in the past talked about particular issues, or how they organized their lives.
Perhaps more dangerously, we assume that we know these things, and that our ancestors saw the world in the same way we do.
Topic models give us a perspective that is interpretable but at the same time alien, based on patterns in documents and not on our own conceptions of how things should be.

Time is a critical variable in the study of historical documents.
Although many modern collections have a significant aspect of time variation (see for example scientometrics), time is a defining element of historical research.
Collections of historical documents are necessarily situated in a time other than our own, but also tend to cover long periods --- decades or even centuries.
As a result, many of the examples cited in this chapter organize documents along a temporal axis.
The associated analysis is particularly concerned with how language, as reflected in topic concentrations and topic contents, changes over time.

This chapter is organized around different formats for historical documents.
A recurring focus is the desire to plot events and discourses against time.
We begin with historical newspapers, which are relatively close to the modern news articles that are a more familiar use case in topic modeling.
We then consider other forms of historical records, such as annals and diaries.
These demonstrate the flexibility of topic modeling, including a corpus not in English and corpus in English with irregular spelling.
Finally, we consider studies of historical scholarly literature.

%A useful resource:
%Clay Templeton, Topic Modeling in the Humanities: An Overview.\footnote{http://mith.umd.edu/topic-modeling-in-the-humanities-an-overview/}

\section{Newspapers}

\citet{newman-06} present an example of topic modeling on historical newspapers, in a collection of articles from the {\em Pennsylvania Gazette} from 1728 to 1800.\footnote{http://www.accessible-archives.com/}
These articles comprise 25 million word tokens in articles and advertisements, and cover several generations of everyday life before, during, and after the founding of the United States of America.
The authors contrast their study to manually created keyword-based indexes, which focus on specific terms and can be applied inconsistently across large corpora.
Spurious patterns in index term use could complicate historical research.
They cite an example of the tag {\em adv}, which is used extensively in the early and late decades of the corpus, but not in the middle.
The topic-based approach is attractive because it is consistent across the collection (as long as the terms used in the documents are themselves consistent) and because it operates at a more abstract semantic level, reducing the chance that modern historians miss key terms.

They compare three methods for finding semantic dimensions, latent semantic analysis \citep{deerwester-90}, k-means clustering, and a topic model \citep{hofmann-99}.
The difference between these methods can be described in terms of expressivity.
LSA is effective at embedding word types and documents in a low-dimensional space, but the individual dimensions of this space are not interpretable as themes.
LSA is too expressive: it places no constraints, such as positivity, on the learned dimensions, and therefore produces uninterpretable results that nevertheless fit the document set well.
The k-means clustering is more similar to the topic model, and more successful at finding recognizable themes.
But it is also prone to repeating similar clusters with small variations.
Because of the single-membership assumption (a document can only belong to one cluster), the clustering model cannot represent documents with varying combinations of somewhat independent themes.
The k-means model is therefore insufficiently expressive: it it forced to ``waste'' clusters on frequent combinations of simpler themes.
The topic model, in contrast, has both modeling flexibility along with sufficient  constraints to support interpretable results.

The authors find that the learned topics are a good representation of dynamics in the corpus, although not always in a direct manner.
There is a large increase in discussions of politics in the period immediately around the American Revolution ({\em state government constitution law united power}).
There is also evidence of economic factors: a topic relating to descriptions of cloth ({\em silk cotton ditto white black linen}) rises in the 1750s, but then declines as Americans turned to domestic ``homespun'' cloth production in response to British trade policies.
Other topics point to more subtle changes in language.
A topic that is less immediately interpretable ({\em  say thing might think own did}) corresponds to a series of long ``public letters'' that contain more academic ``argument making''.



Nelson\footnote{Mining the Dispatch, http://dsl.richmond.edu/dispatch/} studies topics in Civil War-era newspapers, including the Confederate paper of record, the Richmond Daily Dispatch.
Like Block and Newman, Nelson's goal is to organize the collection into themes and to measure the variation in prevalence of those themes over time.
The web interface highlights a temporal view of the collection as a series of topic-specific time series.
The mode of analysis is neither fully automated nor manual, but rather combines the two approaches.
Nelson manually labels the topics and groups them into larger categories such as ``slavery'', ``nationalism and patriotism'', ``soldiers'', and ``economy''.

He validates the model by comparing topics to a known and previously annotated category, the ``fugitive slave ads''.
These documents were pre-photographic descriptions of runaway slaves, and have a specific language consisting of aspects of personal appearance and possible locations where enslaved people might have  hidden.
He finds a near perfect correspondence between the prevalence over time of manually labeled fugitive slave ads and documents that have a high concentration of a specific topic, which places high probability on terms such as {\em reward, years,} and {\em color} (manual labels were not used  in training the model).
Nelson notes that few if any of these documents are assigned completely to this topic: he uses a cutoff of 21.5\% as a criterion.

Nelson's larger-scale groupings of topics pick out threads of discourse that may or may not be correlated over time.
The model identifies three topics that have similar temporal distribution, peaking at the beginning of the war in 1861 and largely disappearing afterwards.
These are related but distinct themes: anti-Northern sentiment expressed in poetic form, anti-Northern sentiment expressed in vitriolic prose, and discussion of secession.
All three form aspects of the same process, the rhetorical push for war.
Other related topics have slightly different temporal distributions.
Nelson groups six topics related to soldiers, and displays them in the order of their maximum concentration over time.
They move from ``military recruitment'' and ``orders to report'' to later topics related to ``deserters'', ``casualties'', and ``war prisoners.''
Again, these are related themes but rather than comprising a single event they trace the development of the increasingly dire military situation of the Confederacy.

\citet{yang-11-historical} model a collection of historical newspapers from Texas spanning from the end of the Civil War to the present day.
The goal is both exploratory, to find out about the interests of Texans through the 19th and 20th centuries, and {\em semi-exploratory}, to find out more about the history and context of specific, pre-specified themes such as cotton production.
In the topic model setting, semi-exploratory analysis starts by identifying one or more topics that seem to correspond to the theme of interest, and then using those topics as a axis of investigation into the corpus.
For example, a historian considered documents that exhibit topics related to {\em cotton}, and the topics that co-occur in those documents.
The study also led to more fully exploratory results.
A topic related to the battle of San Jacinto, the final conflict in the Texas Revolution that led to separation from Mexico, appeared earlier than expected.
Further investigation suggested that the significance of the pivotal battle of San Jacinto was established much earlier than historians had previously anticipated.

The Texas newspaper study raises several interesting methodological issues relating to pre-processing and iterative modeling.
The authors put considerable work into dealing with the quality of digitization.
There are many factors that affect the quality of digitized historical newspapers, from the quality of the original printing to scanning, article segmentation, and optical character recognition (OCR).
For this study extensive work was applied to automated spelling correction.
Another notable factor in this study is its prominent use of multiple topic models.
In many cases there is a tacit assumption that a single corpus should result in a single model, but in practice modeling is often iterative, and intimately bound to the development of pre-processing systems.
\cite{yang-11-historical} train different models on different temporal slices of the corpus.
Although there is some advantage to maintaining a consistent topic space over time, dividing the corpus into separate sections has certain advantages.
In this case, historians were interested in the context of specific historic periods, such as the full run of a a newspaper in one of several pivotal years, that are smaller than the full corpus but yet too large to be read easily.
The authors also describe an iterative workflow that involves comparing topic model output after each of several pre-processing steps.
Topic models are often effective at identifying consistent data-preparation errors, such as end-of-line hyphenation and consistent OCR errors.

\section{Historical Records}

Other types of records besides newspapers are of interest, and present their own challenges.
In this section we consider two case studies, in which the simplicity of the bag-of-words document model is an asset because it allows for substantial variability in spelling and language, both in English and in other languages.

\citet{erlin2017topic} search for work related to epistemology in a large corpus of English and German books.
They ``seed'' the models for each language with a small set of query words that the authors expect to be related to that subject.
This approach is closer to standard information retrieval than many other topic model applications, since the model is used both as a way of organizing the corpus and as a way of focusing attention on specific aspects.
Their use of a topic model differs from standard IR in that they are more deliberately open to related terms and concepts: the field of epistemology is expected to be broad, and more likely to be represented by a combination of words than by any one query.

\citet{miller-13} uses Chinese records to investigate the meaning of
the word {\em zei}, or ``bandit'' in Qing dynasty China (1644--1912). The word by
itself can imply several different forms of anti-social behavior,
which are difficult to distinguish from word frequencies alone. A
topic model uses contextual information to separate these effects.

The application of topic models in Chinese highlights the importance of tokenization.
We usually receive documents in the form of long strings, but we are interested in identifying {\em tokens} that are short strings with a specific meaning.
Breaking a document into distinct tokens is an often-overlooked part of the document analysis process.
In European languages we can achieve good results simply by separating strings of letter characters from sequences of non-letter characters, although there are many special cases.
Tokens may contain non-letter characters such as apostrophes and hyphens, and may span multiple words ({\em Queen Victoria}, {\em black hole}).
In many East Asian writing systems we cannot rely on orthographic conventions to identify tokens.
Miller argues that in Classical Chinese a single character can be treated as a token without a strong negative impact on modeling, but for Japanese and modern Chinese we must often rely on pre-processing tools that are themselves potentially unreliable.

%\jbgcomment{Could we get a figure for the months?  I think that would be a nice addition}

Cameron Blevins\footnote{http://www.cameronblevins.org/posts/topic-modeling-martha-ballards-diary/} models the diary of Martha Ballard (1735--1812), a revolutionary war-era midwife who recorded entries over 27 years. The model provides a useful way to discover connections between words and repeated discourses.
As with other historical corpora, Blevins focuses on the connection between topics and time.
Specific events, like a birth, can be highlighted by looking at spikes in a certain topic in the day-to-day time series.
But larger trends are also evident.
As a calibration experiment, Blevins measures the association of a topic that appears to refer to cold weather ({\em cold, windy, chilly, snowy, air}) to months of the year.
As expected, the concentration of this topic is lowest from May to August, rises from September to January, and falls from February to April.

Blevins identifies several other topics that appear to change in their concentration over time.
Two topics involving house work, focusing roughly on cleaning and cooking, respectively, appear to be correlated in time, and rise over the decades.
Blevins connects this finding to suggestions that as Ballard grew older and her children moved away, she had less help from family members.
A more subtle topic involves descriptions of fatigue and illness.
This topic also increases over time, and appears to correlate with the housework topics, except in the last year of the diary, where fatigue and illness reach their highest concentration and housework declines.

This analysis exemplifies the exploratory nature of topic modeling: by themselves, these observations are not conclusive, but they are suggestive and point to areas of further analysis.
A scholar might take the diary entries that score high on an individual topic as a reading list, and determine how well a particular automatically detected discourse maps to themes in Ballard's personal experience.
For example, one might check whether Ballard's references to fatigue and illness are referring to herself or to patients.
The model does not tell the whole story, but it points to where stories might lie.

Blevins argues that characteristics of the diary form make it well-suited for topic analysis: ``Short, content-driven entries that usually touch upon a limited number of topics appear to produce remarkably cohesive and accurate topics.''
In addition, the topic model's lack of linguistic sophistication is actually an asset in this case.
The diary is written in a terse style with many abbreviations and with irregular, 18th century spelling: ``mrss Pages illness Came on at Evng and Shee was Deliverd at 11h of a Son which waid 12 lb.''
Models trained on modern text corpora might not even recognize this example as English, but the topic modeling algorithm is still capable of finding semantically meaningful groups of words.



\section{Scholarly Literature}


%\jbgcomment{The definition of secondary literature seems unclear to me, and it's not clear that the problem of copyright has been discussed enough that it's clear that JSTOR is so great as a result (even though it is!)}

The historical record of scholarship is a valuable source for intellectual history.
Many users make use of the JStor ``Data for Research'' API.\footnote{http://dfr.jstor.org/}
The DFR API is an important example, because it provides access to articles that have been scanned by JStor and may be under copyright.
Access to the underlying documents in their original form as readable sequences of words may be restricted for legal or commercial reasons.
DFR provides a simple view into selected articles by only providing the frequency of word unigrams.
While the bag-of-words assumption used by topic models is restrictive, in this case it can be an advantage, because the original sequence of words is not used for inference anyway.

\cite{mimno-12b} studies a collection of Classics journals digitized by JStor to detect changes in the field over the 20th century.
A distinctive aspect of this study is the use of a {\em polylingual} topic model \cite{mimno-09}.
An English-language journal is compared to a German-language journal by learning a common set of topics that each have a vocabulary in both languages.
In other words, a topic has two ``modes'', one in which it emits words drawn from a distribution over English terms, and another in which it emits words drawn from a distribution over German terms.
The linkage between English and German words is constructed using Wikipedia articles.
Wikipedia articles exist in many different languages, and articles in one language often link to comparable articles in another language.
The author first selects English Wikipedia articles matching key terms in the English-language journals, and then collects the German Wikipedia articles that are listed as being comparable to the selected English-language articles.

By training the topic model jointly on the combined corpus of the original journal articles and the comparable Wikipedia articles, the model provides insight into the relative concentration of scholarly interests across the two language communities.
The German-language journal articles contain relatively more work on law and oratory, themes that are present in the English-language articles but less prevalent.
The model also shows a large increase in  interest in poetry in the German journal in the period following the second world war.
In the English journals there is a large increase starting in the 1980s in cultural and economic studies along with critical theory, which does not appear in the German journals.

\citet{riddell-12} also approaches German scholarly literature from the 20th century. He finds that topics align well with authors such as Goethe and subjects such as folklore. Apparent spikes in the use of these topics appear to align with anniversaries of authors (Goethe, the Grimm brothers).
Riddell emphasizes that models are useful in raising issues but not a substitute for scholarship.
He comments that ``it becomes essential that those using topic models validate the description provided by a topic model by reference to something other than the topic model itself.''

\citet{Goldstone-14} use a topic model as a tool to structure an exploration of a corpus that spans more than a century.
They are interested both in changes at the topic level and at the level of word use within topics.
For these authors the appeal of topic modeling is that models are better able to represent contextual meaning than simple lists of keywords. They write that ``[t]he meanings
of words are shifting and context-dependent. For this reason, it’s risky to
construct groups of words that we imagine are equivalent to some predetermined
concept.''

They analyze the proceedings of the Modern Language Association to find shifts in focus in the field of English literature.
A model trained with 150 topics on 21,000 articles identifies a topic associated with descriptions of violence: {\em power,
violence, fear, blood, death, murder, act, guilt}. Using a temporal plot they argue that the concentration of this topic is greater in the second half of the 20th century than during the first half.
They contextualize this finding by comparing the frequency of these words in a more general corpus from Google ngrams; there is no comparable change.
This approach holds topic fixed and searches for associated words.
They then pivot and hold the word ``power'' fixed and search for associated topics.
In this case the {\em violence} topic actually appears to be relatively stable in its association with the target word. The largest increase is in a different topic characterized by the words {\em own power text form}, in which context it appears almost exclusively after 1980.

In this chapter we have focused on works in which the temporal axis is of primary concern.
When we consider newspapers, historical records, and historical scholarly journals we are looking not just for the topical foci of each time period, but how those topics shift in concentration as they are influenced by historical events.
Our consideration of scholarly journals leads directly into our next chapter on the study of a much larger and temporally variable literature, the study of science.
